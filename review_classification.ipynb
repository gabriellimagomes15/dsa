{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICADOR DE REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DADOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##carregando dados, filtrando-os e salvando e um novo objeto\n",
    "\n",
    "dados = pd.read_csv('data/reviewFinal.csv',encoding='latin-1')\n",
    "corpus = pd.DataFrame()\n",
    "listTitle = []\n",
    "listRecom = []\n",
    "prediTitle = []\n",
    "\n",
    "for i, r in dados.iterrows():\n",
    "    if r['recommend'] != 'NI' and r['title'] != \"\" and r['title'] is not np.nan: # and r['site'] == \"glassdoor\":\n",
    "        listTitle.append(r['title'])\n",
    "        listRecom.append(r['recommend'])\n",
    "    elif r['recommend'] == 'NI' and r['title'] is not np.nan:\n",
    "        prediTitle.append(r['title'])\n",
    "\n",
    "## criando objeto para encoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus['title']     = listTitle\n",
    "corpus['recommend'] = listRecom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GERANDO LINHAS PARA DADOS DE TREINO E TESTE\n",
    "x = [ i for i in range(len(corpus))]\n",
    "shuffle(x)\n",
    "\n",
    "rows_train =  x[0:round( len(corpus) * .80)] #25000\n",
    "rows_test  = x[round( len(corpus) * .80):(len(corpus))]\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LIMPANDO TEXTO\n",
    "stemmerEng  = SnowballStemmer(\"english\")\n",
    "stemmerPort = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "sClear = []\n",
    "tr = str.maketrans(\"\", \"\", string.punctuation)\n",
    "i = 0\n",
    "for i,text in corpus.iterrows():    \n",
    "    #print(text['title'].split())\n",
    "    clear = \"\"\n",
    "    for word in text['title'].split():        \n",
    "        word = word.lower() ## CONVERTENDO PARA MINUSCULO\n",
    "        word = word.translate(tr) ##REMOVENDO PONTUAÇÕES        \n",
    "        word = re.sub(\"\\d\",\" \",word) ## REMOVENDO NUMEROS\n",
    "        word = stemmerEng.stem(word) ## STEMM\n",
    "        word = stemmerPort.stem(word) ## STEMM\n",
    "        \n",
    "        clear = clear + ' ' + word\n",
    "        clear = re.sub(\"\\s+\",\" \",clear) ## REMOVENDO ESPAÇOS DUPLICADOS\n",
    "        clear = clear.strip()\n",
    "\n",
    "        \n",
    "    sClear.append(clear)\n",
    "    text['title'] = clear\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediTitleClean = []\n",
    "for title in prediTitle:\n",
    "    clear = \"\"\n",
    "    for word in title.split():        \n",
    "        word = word.lower() ## CONVERTENDO PARA MINUSCULO\n",
    "        word = word.translate(tr) ##REMOVENDO PONTUAÇÕES        \n",
    "        word = re.sub(\"\\d\",\" \",word) ## REMOVENDO NUMEROS\n",
    "        word = stemmerEng.stem(word) ## STEMM\n",
    "        word = stemmerPort.stem(word) ## STEMM\n",
    "        \n",
    "        clear = clear + ' ' + word\n",
    "        clear = re.sub(\"\\s+\",\" \",clear) ## REMOVENDO ESPAÇOS DUPLICADOS\n",
    "        clear = clear.strip()\n",
    "        \n",
    "    prediTitleClean.append(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1} {0, 1}\n"
     ]
    }
   ],
   "source": [
    "train   = corpus.iloc[rows_train, [0]]\n",
    "train   = train['title'].tolist()\n",
    "train_y = corpus.iloc[rows_train, [1] ] \n",
    "train_y = encoder.fit_transform(train_y)\n",
    "\n",
    "test   = corpus.iloc[rows_test, [0]]\n",
    "test   = test['title'].tolist()\n",
    "test_y = corpus.iloc[rows_test, [1]]\n",
    "test_y = encoder.fit_transform(test_y)\n",
    "\n",
    "print(set(train_y), set(test_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 0 1 1]\n",
      "      recommend\n",
      "56185       Yes\n",
      "40744       Yes\n",
      "6424        Yes\n",
      "63958       Yes\n",
      "28019        No\n",
      "83669       Yes\n",
      "25613       Yes\n",
      "43749       Yes\n",
      "53547       Yes\n",
      "49202       Yes\n",
      "68538       Yes\n",
      "41214       Yes\n",
      "21807        No\n",
      "82821        No\n",
      "31982       Yes\n",
      "54472       Yes\n",
      "72866       Yes\n",
      "17368        No\n",
      "62822       Yes\n",
      "58147        No\n",
      "85315       Yes\n",
      "37526        No\n",
      "80834       Yes\n",
      "57052       Yes\n",
      "17171       Yes\n",
      "57297        No\n",
      "6638        Yes\n",
      "12608       Yes\n",
      "69099        No\n",
      "37233       Yes\n",
      "...         ...\n",
      "61462        No\n",
      "50781       Yes\n",
      "82465        No\n",
      "19260       Yes\n",
      "23961        No\n",
      "493         Yes\n",
      "47483       Yes\n",
      "45095        No\n",
      "38312       Yes\n",
      "18603       Yes\n",
      "66287       Yes\n",
      "33286        No\n",
      "54153       Yes\n",
      "5874         No\n",
      "64939       Yes\n",
      "52457       Yes\n",
      "49016        No\n",
      "70938        No\n",
      "68098       Yes\n",
      "32641        No\n",
      "17851        No\n",
      "21372       Yes\n",
      "13758       Yes\n",
      "60003        No\n",
      "45164       Yes\n",
      "73135        No\n",
      "73573       Yes\n",
      "47768        No\n",
      "24494       Yes\n",
      "32248       Yes\n",
      "\n",
      "[68870 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)\n",
    "print(corpus.iloc[rows_train, [1] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELOS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES MULTINOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68870, 8766)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criando countVectorizer\n",
    "stopWords = stopwords.words('english') \n",
    "[stopWords.append(w) for w in stopwords.words('portuguese')]\n",
    "\n",
    "count_vect     = CountVectorizer(stop_words = stopWords)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "count_vect.vocabulary_.get(u'algorithm')\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68870, 8766)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando TF-IDM\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf     = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CRIANDO OBJETO NAIVE BAYES E TREINANDO O MODELO\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FAZENDO TRANSFORMAÇÃO NOS DADOS DE TESTE E TESTANDO O MODELO NB\n",
    "X_new_counts = count_vect.transform(test)\n",
    "X_new_tfidf  = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2370  3344]\n",
      " [  734 10769]]\n",
      "\n",
      " acuracia :  0.763141081489\n"
     ]
    }
   ],
   "source": [
    "## Verificando acuracia do modelo\n",
    "print( confusion_matrix(test_y, predicted) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predicted) )\n",
    "\n",
    "# acuracia :  0.7615191287349903\n",
    "# 0.763141081489\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classificando comentários sem recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_predict_counts = count_vect.transform(prediTitleClean)\n",
    "X_predict_tfidf  = tfidf_transformer.transform(X_predict_counts)\n",
    "\n",
    "recom_predicted = clf.predict(X_predict_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label (yes ou no) dos valores previstos\n",
    "#np.unique(recom_predicted,return_counts=True)\n",
    "\n",
    "labelPred = [ 'Yes' if rec == 1 else 'No' for rec in recom_predicted ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### salvando previsoes de recomendações\n",
    "pd.DataFrame({'predRecom': labelPred,'title': prediTitle}).to_csv('data/recommendPred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictBIN = nb.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2940  4252]\n",
      " [  903 13391]]\n",
      "\n",
      " acuracia :  0.7555152192125105\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(test_y, predicted) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predictBIN) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criando modelo SVC com Pipeline\n",
    "modeloSVC  = Pipeline([('vect', TfidfVectorizer(stop_words=stopwords.words('english'))), \n",
    "                    ('clf', SVC(kernel = 'linear', probability = True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#treinando modelo\n",
    "modeloSVC.fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictSVC = modeloSVC.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( confusion_matrix(test_y, predictSVC) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predictSVC) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  927  6265]\n",
      " [  280 14014]]\n",
      "\n",
      " acuracia :  0.6953830401191473\n"
     ]
    }
   ],
   "source": [
    "modeloSVM = Pipeline([('vect', CountVectorizer(stopwords.words('english'))),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=500, tol=None)),\n",
    "])\n",
    "modeloSVM.fit(train, train_y)  \n",
    "\n",
    "predicted = modeloSVM.predict(test)\n",
    "print( confusion_matrix(test_y, predicted) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predicted) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIM!!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
